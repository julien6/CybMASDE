{
    "batch_mode": "truncate_episodes",
    "train_batch_size": 50,
    "sgd_minibatch_size": 50,
    "lr": 0.0005,
    "entropy_coeff": 0.01,
    "num_sgd_iter": 2,
    "clip_param": 0.3,
    "use_gae": "True",
    "lambda": 1.0,
    "vf_loss_coeff": 1.0,
    "kl_coeff": 0.2,
    "vf_clip_param": 10.0,
    "model": {
        "custom_model": "Centralized_Critic_Model",
        "custom_model_config": {
            "env": "mpe",
            "env_args": {
                "continuous_actions": "False",
                "max_cycles": 25,
                "map_name": "simple_spread"
            },
            "mask_flag": "False",
            "global_state_flag": "False",
            "opp_action_in_cc": "True",
            "agent_level_batch_update": "False",
            "force_coop": "True",
            "local_mode": "False",
            "share_policy": "all",
            "evaluation_interval": 50,
            "framework": "torch",
            "num_workers": 1,
            "num_gpus": 0,
            "num_cpus_per_worker": 1,
            "num_gpus_per_worker": 0,
            "checkpoint_freq": 500,
            "checkpoint_end": "True",
            "restore_path": {
                "model_path": "",
                "params_path": ""
            },
            "stop_iters": 9999999,
            "stop_timesteps": 2000000,
            "stop_reward": 999999,
            "seed": 321,
            "local_dir": "",
            "model_arch_args": {
                "hidden_state_size": 256,
                "core_arch": "mlp",
                "fc_layer": 2,
                "out_dim_fc_0": 128,
                "out_dim_fc_1": 64,
                "encode_layer": "16-32"
            },
            "algorithm": "mappo",
            "space_obs": "Dict(obs:Box([-100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100. -100.], [100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100. 100.], (18,), float32))",
            "space_act": "Discrete(5)",
            "num_agents": 3,
            "episode_limit": 25,
            "policy_mapping_info": {
                "simple_adversary": {
                    "description": "one team attack, one team survive",
                    "team_prefix": "(\"adversary_\", \"agent_\")",
                    "all_agents_one_policy": "False",
                    "one_agent_one_policy": "True"
                },
                "simple_crypto": {
                    "description": "two team cooperate, one team attack",
                    "team_prefix": "(\"eve_\", \"bob_\", \"alice_\")",
                    "all_agents_one_policy": "False",
                    "one_agent_one_policy": "True"
                },
                "simple_push": {
                    "description": "one team target on landmark, one team attack",
                    "team_prefix": "(\"adversary_\", \"agent_\")",
                    "all_agents_one_policy": "False",
                    "one_agent_one_policy": "True"
                },
                "simple_tag": {
                    "description": "one team attack, one team survive",
                    "team_prefix": "(\"adversary_\", \"agent_\")",
                    "all_agents_one_policy": "False",
                    "one_agent_one_policy": "True"
                },
                "simple_spread": {
                    "description": "one team cooperate",
                    "team_prefix": "(\"agent_\",)",
                    "all_agents_one_policy": "True",
                    "one_agent_one_policy": "True"
                },
                "simple_reference": {
                    "description": "one team cooperate",
                    "team_prefix": "(\"agent_\",)",
                    "all_agents_one_policy": "True",
                    "one_agent_one_policy": "True"
                },
                "simple_world_comm": {
                    "description": "two team cooperate and attack, one team survive",
                    "team_prefix": "(\"adversary_\", \"leadadversary_\", \"agent_\")",
                    "all_agents_one_policy": "False",
                    "one_agent_one_policy": "True"
                },
                "simple_speaker_listener": {
                    "description": "two team cooperate",
                    "team_prefix": "(\"speaker_\", \"listener_\")",
                    "all_agents_one_policy": "True",
                    "one_agent_one_policy": "True"
                }
            },
            "agent_name_ls": [
                "agent_0",
                "agent_1",
                "agent_2"
            ]
        }
    },
    "seed": 321,
    "env": "mpe_simple_spread",
    "num_gpus_per_worker": 0,
    "num_gpus": 0,
    "num_workers": 1,
    "multiagent": {
        "policies": [
            "shared_policy"
        ],
        "policy_mapping_fn": "<function run_cc.<locals>.<lambda> at 0x7d6bbdb4c1f0>"
    },
    "framework": "torch",
    "evaluation_interval": 50,
    "simple_optimizer": "False"
}